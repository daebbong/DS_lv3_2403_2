{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa73290",
   "metadata": {},
   "source": [
    "## 문제 6\n",
    "\n",
    "**Kaggle 형** train_prob.csv로 문제 target을 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 target 예측하여 다음과 같은 형식의 answer6.csv를 만들어라.\n",
    "\n",
    "id, target\n",
    "\n",
    "0, 6.9\n",
    "\n",
    "5, 7.8\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "**평가지표**\n",
    "\n",
    "$RMSE(Y, \\hat{Y}) = \\sqrt{\\frac{1}{n}\\sum^{n}_{i=1}(y_i-\\hat{y_i})^2}$\n",
    "\n",
    "**강사: 멀티캠퍼스 강선구(sunku0316.kang@multicampus.com, sun9sun9@gmail.com)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5d2a9",
   "metadata": {},
   "source": [
    "# 모수적 모델 특히 선형모델에서는 가변수를 만들때 drop='first'가 꼭 필요합니다\n",
    "\n",
    "**※ 의사 결정 나무와 같은 비모수 모델에서는 drop='first'는 불필요하여 상관이 없습니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47ae8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d228960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col=['id'])\n",
    "df_test = pd.read_csv('test_prob.csv', index_col=['id'])\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b19d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat3 {'B': 'C'} [83634, 147361, 9005]\n",
      "cat4 {'A': 'B', 'D': 'B'} [239397, 603]\n",
      "cat6 {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'} [234203, 5145, 652]\n",
      "cat7 {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'} [4606, 19784, 214027, 1583]\n",
      "cat8 {'B': 'G', 'F': 'E'} [30338, 96743, 2953, 76085, 33881]\n",
      "cat9 {'C': 'H', 'D': 'B', 'E': 'L'} [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968]\n"
     ]
    }
   ],
   "source": [
    "# 처리 과정에 필요하 내용들을 list 형태로 구성합니다.\n",
    "repl_list = [\n",
    "    ('cat3', {\"B\": \"C\"}, [83634, 147361, 9005]),\n",
    "    ('cat4', {\"A\": \"B\", \"D\": \"B\"}, [239397, 603]), \n",
    "    ('cat6', {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'}, [234203, 5145, 652]),\n",
    "    ('cat7', {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'}, [4606, 19784, 214027, 1583]),\n",
    "    ('cat8', {'B': 'G', 'F': 'E'}, [30338, 96743, 2953, 76085, 33881]),\n",
    "    ('cat9', {'C': 'H', 'D': 'B', 'E': 'L'}, [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968])\n",
    "]\n",
    "# 반복문 처리 내용들을 수행합니다.\n",
    "for c, d, cnt in repl_list:\n",
    "    print(c, d, cnt)\n",
    "    # 치환후 내용을 s_repl에 저장합니다\n",
    "    s_repl = df_train[c].replace(d)\n",
    "    # 치환결과를 확인합니다.\n",
    "    if not (s_repl.nunique() == len(cnt) and (s_repl.value_counts().sort_index() == cnt).all()):\n",
    "        print(\"Error\", c)\n",
    "        break\n",
    "    df_train[c] = s_repl\n",
    "     # 일부러 cat9에 test에만 등장하는 수준을 만듭니다.\n",
    "    if c != 'cat9':\n",
    "        df_test[c] = df_test[c].replace(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558052c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [i for i in np.arange(0, 1.01, 0.01)]\n",
    "# 나머지 변수에 대해서도 해당 파생 변수를 만들어 줍니다.\n",
    "for i in range(0, 14):\n",
    "    col = 'cont{}'.format(i)\n",
    "    q_val = df_train[col].quantile(q)\n",
    "    q_val.iloc[[0, -1]] = [-np.inf, np.inf]\n",
    "    q_range = pd.cut(df_train[col], bins=q_val)\n",
    "    q_mean = df_train.groupby(q_range)['target'].mean()\n",
    "    df_train[col + '_q'] = q_range.map(q_mean).astype('float')\n",
    "    df_test[col + '_q'] = pd.cut(df_test[col], bins=q_val).map(q_mean).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d399f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import ShuffleSplit, KFold \n",
    "\n",
    "cv = KFold(n_splits=5, random_state=123)\n",
    "# train(80%)/test(20%) 한 번으로 검증합니다. XGB, RF등 오래 걸리는 모델을 위해 사용합니다.\n",
    "ss = ShuffleSplit(n_splits=1, train_size=0.8, random_state=123)\n",
    "\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id')\n",
    "X = df_test.columns.tolist() + ['cont{}_q'.format(i) for i in range(14)]\n",
    "\n",
    "cat_cols = ['cat{}'.format(i) for i in range(10)]\n",
    "cont_cols = ['cont{}'.format(i) for i in range(14)]\n",
    "cont_q_cols = ['cont{}_q'.format(i) for i in range(14)]\n",
    "\n",
    "# 위에서 발생한 leak을 바로 잡아 교차검증을 합니다.\n",
    "q = [i for i in np.arange(0, 1.01, 0.01)]\n",
    "def eval_model(model, sp):\n",
    "    score_train, score = list(), list()\n",
    "    for train_idx, test_idx in sp.split(df_train):\n",
    "        df_cv_train, df_cv_test = df_train.iloc[train_idx].copy(), df_train.iloc[test_idx].copy()\n",
    "        # 검증셋에서 train으로 파생변수를 만들고\n",
    "        # 검증셋의 test(겹외셋)에 검증셋의 train으로 만든 통계값(mean)을 반영합니다.\n",
    "        for i in range(0, 14):\n",
    "            col = 'cont{}'.format(i)\n",
    "            qt = df_cv_train[col].quantile(q)\n",
    "            qt.iloc[[0, -1]] = [-np.inf, np.inf]\n",
    "            q_range = pd.cut(df_cv_train[col], bins=qt)\n",
    "            q_mean = df_cv_train.groupby(q_range)['target'].mean()\n",
    "            df_cv_train[col + '_q'] = q_range.map(q_mean).astype('float')\n",
    "            df_cv_test[col + '_q'] = pd.cut(df_cv_test[col], bins=qt).map(q_mean).astype('float')\n",
    "        model.fit(df_cv_train[X], df_cv_train['target'])\n",
    "        score_train.append(-(mean_squared_error(df_cv_train['target'], model.predict(df_cv_train[X]))) ** 0.5)\n",
    "        score.append(-(mean_squared_error(df_cv_test['target'], model.predict(df_cv_test[X]))) ** 0.5)\n",
    "    return score_train, score\n",
    "\n",
    "def choose_model(model):\n",
    "    model.fit(df_train[X], df_train['target'])\n",
    "    prd = model.predict(df_test[X])\n",
    "    pd.DataFrame({\n",
    "        'id': df_test.index.values,\n",
    "        'target': prd\n",
    "    }).to_csv('answer6.csv', index = None)\n",
    "    return prd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7147a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8632710692832337, 0.0029506483961325154, -0.8630391361652678)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 모델을 만들어 봅니다.\n",
    "# handle_unknown을 ignore로 하여 등장하지 않은 수준에 대해 에러가 발생하지 않도록 합니다.\n",
    "# 이 경우 해당 변수의 가변수 모든 값은 0이 됩니다.\n",
    "# handle_unknown = 'ignore'와 drop='first'를 동시에 설정할 수 없습니다.\n",
    "# drop='first'를 생략하면 어떤 문제가 발생하는지 확인하기 위해 drop='first'를 제외합니다.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ('std', StandardScaler(), cont_cols),\n",
    "])\n",
    "reg_lr = make_pipeline(\n",
    "    ct, \n",
    "    LinearRegression()\n",
    ")\n",
    "result = eval_model(reg_lr, cv)\n",
    "np.mean(result[1]), np.std(result[1]), np.mean(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d410500e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3514777007.3882246"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd = choose_model(reg_lr)\n",
    "# 자가 채점을 해봅니다.\n",
    "# 검증시에는 문제가 보이지 않지만\n",
    "# 제출한 test 결과에는 심한 결합이 보입니다.\n",
    "# 변수마다 하나의 가변수를 제외하지 않아, 완전한 다중공선성에 의한\n",
    "# 모델의 불안정성이 심하게되어 문제를 일으킨 것입니다.\n",
    "mean_squared_error(df_ans['target'], prd) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdb71c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.88603061e+09,  8.88603061e+09, -8.38064646e+09, -8.38064646e+09,\n",
       "       -9.88098395e+09, -9.88098395e+09,  8.58976592e+09,  8.58976592e+09,\n",
       "        8.58976592e+09,  1.22720922e+11,  1.22720922e+11,  7.02048573e+09,\n",
       "        7.02048573e+09,  7.02048573e+09,  7.02048573e+09,  4.94934768e+10,\n",
       "        4.94934768e+10,  4.94934768e+10,  1.25524042e+11,  1.25524042e+11,\n",
       "        1.25524042e+11,  1.25524042e+11, -4.84038575e+09, -4.84038575e+09,\n",
       "       -4.84038575e+09, -4.84038575e+09, -4.84038575e+09,  9.68634328e+10,\n",
       "        9.68634328e+10,  9.68634328e+10,  9.68634328e+10,  9.68634328e+10,\n",
       "        9.68634328e+10,  9.68634328e+10,  9.68634328e+10,  9.68634328e+10,\n",
       "        9.68634328e+10,  9.68634328e+10,  9.68634328e+10, -5.82885742e-02,\n",
       "        3.45573425e-02,  2.10189819e-03, -5.52368164e-03, -5.50842285e-03,\n",
       "       -5.46493530e-02,  2.36263275e-02,  1.55296326e-02,  6.80694580e-02,\n",
       "        2.72369385e-02, -2.11944580e-02,  5.17578125e-02,  1.56860352e-02,\n",
       "       -5.84411621e-03])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회귀 계수에 큰 값이 채워져 있습니다.\n",
    "# 불안정한 모델이 되었습니다.\n",
    "reg_lr.fit(df_train[X], df_train['target'])\n",
    "reg_lr[1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2e53c",
   "metadata": {},
   "source": [
    "# 진단 및 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07e887ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat3           {}\n",
       "cat4           {}\n",
       "cat6           {}\n",
       "cat7           {}\n",
       "cat8           {}\n",
       "cat9    {E, C, D}\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 따라서 Linear과 같은 모수적 모델에서는 모델의 안정성을 위해, \n",
    "# drop='first'를 반드시 해주어야 합니다. \n",
    "# Test만 등장하는 범주값을 제거해 줍니다.\n",
    "\n",
    "# Test에만 등장하는 범주값을 봅니다.\n",
    "\n",
    "pd.concat([\n",
    "    df_train[[k[0] for k in repl_list]].apply(lambda x: set(x.unique())).rename('train_level'),\n",
    "    df_test[[k[0] for k in repl_list]].apply(lambda x: set(x.unique())).rename('test_level')\n",
    "], axis=1).apply(lambda x: x['test_level'] - x['train_level'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f03f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미등장 수준을 가장 자주 등장하는 범주값으로 바꿉니다.\n",
    "df_test['cat9'] = df_test['cat9'].replace({'D': np.nan, 'E': np.nan, 'C': np.nan})\n",
    "df_test['cat9'] = df_test['cat9'].fillna(df_train['cat9'].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60d0fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8632456423386847, 0.0029474142614306633, -0.8630025788522048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop='first' 설정을 해줍니다.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)])\n",
    "])\n",
    "X_lr = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)]\n",
    "reg_lr = make_pipeline(ct, LinearRegression())\n",
    "scores_train, scores = eval_model(reg_lr, cv)\n",
    "np.mean(scores), np.std(scores), np.mean(scores_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fcc880e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657268588416211"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test에 등장하지 않은 변수값을 train에 등장하는 범주값으로 처리해주었고,\n",
    "# drop='first'를 통해 완전한 다중공선성이 발생하지 않도록 했습니다.\n",
    "# 문제가 해결됩니다.\n",
    "prd = choose_model(reg_lr)\n",
    "mean_squared_error(df_ans['target'], prd) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5d56b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14737833,  0.16983335,  0.24147158,  0.10693804,  0.03994362,\n",
       "        0.15713566,  0.03681214, -0.17486971,  0.03074087,  0.21519861,\n",
       "        0.36870383, -0.00597853, -0.05547379, -0.05870304, -0.00092302,\n",
       "        0.05854559,  0.07181603, -0.10018803,  0.03508515,  0.13365193,\n",
       "        0.1647826 ,  0.08022279, -0.00404722,  0.02865399,  0.09003857,\n",
       "        0.21092791,  0.09276305,  0.09655687,  0.07017521, -0.28413913,\n",
       "        0.14685393,  0.01069457, -0.02323074, -0.02707619, -0.23571329,\n",
       "        0.12262252,  0.07588697,  0.30830852,  0.13373422, -0.10509757,\n",
       "        0.22408617,  0.0712212 , -0.02577207])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회귀 계수를 출력해보면 지나치게 큰 계수가 나왔던 문제가 완전히 해결됩니다.\n",
    "reg_lr.fit(df_train[X], df_train['target'])\n",
    "reg_lr[1].coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
